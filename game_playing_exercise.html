<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <title>AIMA Exercises</title>


    <!-- Custom fonts -->
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    

    <!-- Custom styles -->
    <link href="css/clean-blog.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">

    <!-- jQuery library -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

    <!-- Latest compiled JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
            tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
                              });
    </script>
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>

    
    

  </head>

  <body>
      
    <!-- Navigation -->
      <nav class="navbar navbar-expand-lg navbar-light bg-light navbar-fixed-top">
  <a class="navbar-brand" href="index.html">AIMA</a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <div class="collapse navbar-collapse" id="navbarSupportedContent">
    <ul class="navbar-nav mr-auto">
      
      <li class="nav-item dropdown">
        <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
          <b>Exercises</b>
        </a>
        <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                <a href="intro_exercise.html" class="dropdown-item">✓ Intro Exercise</a>
			    <a href="agents_exercise.html" class="dropdown-item">Agents Exercise</a>
			    <a href="search_exercise.html" class="dropdown-item">Search Exercise</a>
			    <a href="advanced_search_exercise.html" class="dropdown-item">✓ Advanced Search Exercise</a>
			    <a href="game_playing_exercise.html" class="dropdown-item active">Game Playing Exercise</a>
			    <a href="csp_exercise.html" class="dropdown-item">Csp Exercise</a>
			    <a href="knowledge_logic_exercise.html" class="dropdown-item">Knowledge Logic Exercise</a>
			    <a href="fol_exercise.html" class="dropdown-item">Fol Exercise</a>
			    <a href="logical_inference_exercise.html" class="dropdown-item">Logical Inference Exercise</a>
			    <a href="planning_exercise.html" class="dropdown-item">Planning Exercise</a>
			    <a href="advanced_planning_exercise.html" class="dropdown-item">✓ Advanced Planning Exercise</a>
			    <a href="kr_exercise.html" class="dropdown-item">Kr Exercise</a>
			    <a href="probability_exercise.html" class="dropdown-item">Probability Exercise</a>
			    <a href="bayes_nets_exercise.html" class="dropdown-item">Bayes Nets Exercise</a>
			    <a href="dbn_exercise.html" class="dropdown-item">Dbn Exercise</a>
			    <a href="decision_theory_exercise.html" class="dropdown-item">Decision Theory Exercise</a>
			    <a href="complex_decisions_exercise.html" class="dropdown-item">Complex Decisions Exercise</a>
			    <a href="concept_learning_exercise.html" class="dropdown-item">Concept Learning Exercise</a>
			    <a href="ilp_exercise.html" class="dropdown-item">Ilp Exercise</a>
		            <a href="bayesian_learning_exercise.html" class="dropdown-item">Bayesian Learning Exercise</a>
			    <a href="reinforcement_learning_exercise.html" class="dropdown-item">Reinforcement Learning Exercise</a>
			    <a href="nlp_communicating_exercise.html" class="dropdown-item">Nlp Communicating Exercise</a>
			    <a href="nlp_english_exercise.html" class="dropdown-item">Nlp English Exercise</a>
			    <a href="perception_exercise.html" class="dropdown-item">Perception Exercise</a>
			    <a href="robotics_exercise.html" class="dropdown-item">Robotics Exercise</a>
			    <a href="philosophy_exercise.html" class="dropdown-item">Philosophy Exercise</a>
          <div class="dropdown-divider"></div>
          <a href="future_exercise.html" class="dropdown-item" >Future Exercise</a>
        </div>
      </li>
    </ul>
  </div>
</nav>

<br />

    <!-- Page Header -->
<header><br /><br /><br /></header>
      
      
      

    <!-- Main Content -->
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <div class="post-preview">
            <h5><b>EXERCISES</b></h1>
		   <h1 id="5adversarialsearch">5. Adversarial Search</h1>

<p><strong>5.1</strong> Suppose you have an oracle, $OM(s)$, that correctly predicts the
opponent’s move in any state. Using this, formulate the definition of a
game as a (single-agent) search problem. Describe an algorithm for
finding the optimal move.</p>

<p><strong>5.2</strong> Consider the problem of solving two 8-puzzles.</p>

<ol>
<li><p>Give a complete problem formulation in the style of
Chapter <a href="#/">search-chapter</a>.</p></li>

<li><p>How large is the reachable state space? Give an exact
numerical expression.</p></li>

<li><p>Suppose we make the problem adversarial as follows: the two players
take turns moving; a coin is flipped to determine the puzzle on
which to make a move in that turn; and the winner is the first to
solve one puzzle. Which algorithm can be used to choose a move in
this setting?</p></li>

<li><p>Does the game eventually end, given optimal play? Explain.</p></li>
</ol>

<p>
<b id="pursuit-evasion-game-figure">Figure [pursuit-evasion-game-figure]</b> (a) A map where the cost of every edge is 1. Initially the pursuer $P$ is at
node <strong>b</strong> and the evader $E$ is at node <strong>d</strong>. (b) A partial game tree for this map.
Each node is labeled with the $P,E$ positions. $P$ moves first. Branches marked "?" have yet to be explored.
</p>

<p><img src="http://nalinc.github.io/aima-exercises/Jupyter%20notebook/figures/pursuit-evasion-game.svg" alt="pursuit-evasion-game-figure"  style="width: 100%;" /></p>

<p><strong>5.3</strong> Imagine that, in Exercise [two-friends-exercise], one of
the friends wants to avoid the other. The problem then becomes a
two-player game. We assume now that the players take turns moving. The
game ends only when the players are on the same node; the terminal
payoff to the pursuer is minus the total time taken. (The evader “wins”
by never losing.) An example is shown in
Figure <a href="#pursuit-evasion-game-figure">pursuit-evasion-game-figure</a>.</p>

<ol>
<li><p>Copy the game tree and mark the values of the terminal nodes.</p></li>

<li><p>Next to each internal node, write the strongest fact you can infer
about its value (a number, one or more inequalities such as
“$\geq 14$”, or a “?”).</p></li>

<li><p>Beneath each question mark, write the name of the node reached by
that branch.</p></li>

<li><p>Explain how a bound on the value of the nodes in (c) can be derived
from consideration of shortest-path lengths on the map, and derive
such bounds for these nodes. Remember the cost to get to each leaf
as well as the cost to solve it.</p></li>

<li><p>Now suppose that the tree as given, with the leaf bounds from (d),
is evaluated from left to right. Circle those “?” nodes that would
<em>not</em> need to be expanded further, given the bounds
from part (d), and cross out those that need not be considered
at all.</p></li>

<li><p>Can you prove anything in general about who wins the game on a map
that is a tree?</p></li>
</ol>

<p><strong>5.4</strong> [game-playing-chance-exercise]Describe and implement state
descriptions, move generators, terminal tests, utility functions, and
evaluation functions for one or more of the following stochastic games:
Monopoly, Scrabble, bridge play with a given contract, or Texas hold’em
poker.</p>

<p><strong>5.5</strong> Describe and implement a <em>real-time</em>,
<em>multiplayer</em> game-playing environment, where time is part
of the environment state and players are given fixed time allocations.</p>

<p><strong>5.6</strong> Discuss how well the standard approach to game playing would apply to
games such as tennis, pool, and croquet, which take place in a
continuous physical state space.</p>

<p><strong>5.7</strong> [minimax-optimality-exercise] Prove the following assertion: For every
game tree, the utility obtained by max using minimax
decisions against a suboptimal min will never be lower than
the utility obtained playing against an optimal min. Can
you come up with a game tree in which max can do still
better using a <em>suboptimal</em> strategy against a suboptimal
min?</p>

<p>
<b id="line-game4-figure">Figure [line-game4-figure]</b> The starting position of a simple game.
</p>

<p><img src="http://nalinc.github.io/aima-exercises/Jupyter%20notebook/figures/line-game4.svg" alt="line-game4-figure" /></p>

<p>Player $A$ moves first. The two players take turns moving, and each
player must move his token to an open adjacent space in either
direction.  If the opponent occupies an adjacent space, then a player
may jump over the opponent to the next open space if any. (For
example, if $A$ is on 3 and $B$ is on 2, then $A$ may move back to 1.)
The game ends when one player reaches the opposite end of the board.
If player $A$ reaches space 4 first, then the value of the game to $A$
is $+1$; if player $B$ reaches space 1 first, then the value of the
game to $A$ is $-1$.</p>

<p><strong>5.8</strong> Consider the two-player game described in
Figure <a href="#line-game4-figure">line-game4-figure</a>.</p>

<ol>
<li><p>Draw the complete game tree, using the following conventions:</p>

<ul>
<li><p>Write each state as $(s_A,s_B)$, where $s_A$ and $s_B$ denote
the token locations.</p></li>

<li><p>Put each terminal state in a square box and write its game value
in a circle.</p></li>

<li><p>Put <em>loop states</em> (states that already appear on
the path to the root) in double square boxes. Since their value
is unclear, annotate each with a “?” in a circle.</p></li></ul></li>

<li><p>Now mark each node with its backed-up minimax value (also in
a circle). Explain how you handled the “?” values and why.</p></li>

<li><p>Explain why the standard minimax algorithm would fail on this game
tree and briefly sketch how you might fix it, drawing on your answer
to (b). Does your modified algorithm give optimal decisions for all
games with loops?</p></li>

<li><p>This 4-square game can be generalized to $n$ squares for any
$n > 2$. Prove that $A$ wins if $n$ is even and loses if $n$ is odd.</p></li>
</ol>

<p><strong>5.9</strong> This problem exercises the basic concepts of game playing, using
tic-tac-toe (noughts and crosses) as an example. We define
$X_n$ as the number of rows, columns, or diagonals with exactly $n$
$X$’s and no $O$’s. Similarly, $O_n$ is the number of rows, columns, or
diagonals with just $n$ $O$’s. The utility function assigns $+1$ to any
position with $X_3=1$ and $-1$ to any position with $O_3 = 1$. All other
terminal positions have utility 0. For nonterminal positions, we use a
linear evaluation function defined as ${Eval}(s) = 3X_2(s) + X_1(s) -
(3O_2(s) + O_1(s))$ .</p>

<ol>
<li><p>Approximately how many possible games of tic-tac-toe are there?</p></li>

<li><p>Show the whole game tree starting from an empty board down to depth
2 (i.e., one $X$ and one $O$ on the board), taking symmetry
into account.</p></li>

<li><p>Mark on your tree the evaluations of all the positions at depth 2.</p></li>

<li><p>Using the minimax algorithm, mark on your tree the backed-up values
for the positions at depths 1 and 0, and use those values to choose
the best starting move.</p></li>

<li><p>Circle the nodes at depth 2 that would <em>not</em> be
evaluated if alpha–beta pruning were applied, assuming the nodes are
generated in the optimal order for alpha–beta pruning.</p></li>
</ol>

<p><strong>5.10</strong> Consider the family of generalized tic-tac-toe games, defined as
follows. Each particular game is specified by a set $\mathcal S$ of
<em>squares</em> and a collection $\mathcal W$ of <em>winning
positions.</em> Each winning position is a subset of $\mathcal S$.
For example, in standard tic-tac-toe, $\mathcal S$ is a set of 9 squares
and $\mathcal W$ is a collection of 8 subsets of $\cal W$: the three
rows, the three columns, and the two diagonals. In other respects, the
game is identical to standard tic-tac-toe. Starting from an empty board,
players alternate placing their marks on an empty square. A player who
marks every square in a winning position wins the game. It is a tie if
all squares are marked and neither player has won.</p>

<ol>
<li><p>Let $N= |{\mathcal S}|$, the number of squares. Give an upper bound
on the number of nodes in the complete game tree for generalized
tic-tac-toe as a function of $N$.</p></li>

<li><p>Give a lower bound on the size of the game tree for the worst case,
where ${\mathcal W} = {{,}}$.</p></li>

<li><p>Propose a plausible evaluation function that can be used for any
instance of generalized tic-tac-toe. The function may depend on
$\mathcal S$ and $\mathcal W$.</p></li>

<li><p>Assume that it is possible to generate a new board and check whether
it is a winning position in 100$N$ machine instructions and assume a
2 gigahertz processor. Ignore memory limitations. Using your
estimate in (a), roughly how large a game tree can be completely
solved by alpha–beta in a second of CPU time? a minute? an hour?</p></li>
</ol>

<p><strong>5.11</strong> Develop a general game-playing program, capable of playing a variety of
games.</p>

<ol>
<li><p>Implement move generators and evaluation functions for one or more
of the following games: Kalah, Othello, checkers, and chess.</p></li>

<li><p>Construct a general alpha–beta game-playing agent.</p></li>

<li><p>Compare the effect of increasing search depth, improving move
ordering, and improving the evaluation function. How close does your
effective branching factor come to the ideal case of perfect move
ordering?</p></li>

<li><p>Implement a selective search algorithm, such as B* @Berliner:1979,
conspiracy number search @McAllester:1988, or MGSS*
@Russell+Wefald:1989 and compare its performance to A*.</p></li>
</ol>

<p><strong>5.12</strong> Describe how the minimax and alpha–beta algorithms change for
two-player, non-zero-sum games in which each player has a distinct
utility function and both utility functions are known to both players.
If there are no constraints on the two terminal utilities, is it
possible for any node to be pruned by alpha–beta? What if the player’s
utility functions on any state differ by at most a constant $k$, making
the game almost cooperative?</p>

<p><strong>5.13</strong> Describe how the minimax and alpha–beta algorithms change for
two-player, non-zero-sum games in which each player has a distinct
utility function and both utility functions are known to both players.
If there are no constraints on the two terminal utilities, is it
possible for any node to be pruned by alpha–beta? What if the player’s
utility functions on any state sum to a number between constants $-k$
and $k$, making the game almost zero-sum?</p>

<p><strong>5.14</strong> Develop a formal proof of correctness for alpha–beta pruning. To do
this, consider the situation shown in
Figure <a href="#alpha-beta-proof-figure">alpha-beta-proof-figure</a>. The question is whether
to prune node $n_j$, which is a max-node and a descendant of node $n_1$.
The basic idea is to prune it if and only if the minimax value of $n_1$
can be shown to be independent of the value of $n_j$ .</p>

<ol>
<li><p>Mode $n_1$ takes on the minimum value among its children:
$n_1 = \min(n_2,n_{{21}},\ldots,n_{2b_2})$. Find a similar
expression for $n_2$ and hence an expression for $n_1$ in terms of
$n_j$.</p></li>

<li><p>Let $l_i$ be the minimum (or maximum) value of the nodes to the
*left* of node $n_i$ at depth $i$, whose minimax value
is already known. Similarly, let $r_i$ be the minimum (or maximum)
value of the unexplored nodes to the right of $n_i$ at depth $i$.
Rewrite your expression for $n_1$ in terms of the $l_i$ and
$r_i$ values.</p></li>

<li><p>Now reformulate the expression to show that in order to affect
$n_1$, $n_j$ must not exceed a certain bound derived from the
$l_i$ values.</p></li>

<li><p>Repeat the process for the case where $n_j$ is a min-node.</p></li>
</ol>

<p>
<b id="alpha-beta-proof-figure">Figure [alpha-beta-proof-figure]</b> Situation when considering whether to prune node $n_j$.
</p>

<p><img src="http://nalinc.github.io/aima-exercises/Jupyter%20notebook/figures/alpha-beta-proof.svg" alt="alpha-beta-proof-figure" style="width: 100%;" /></p>

<p><strong>5.15</strong> Prove that the alpha–beta algorithm takes time $O(b^{m/2})$ with optimal
move ordering, where $m$ is the maximum depth of the game tree.</p>

<p><strong>5.16</strong> Suppose you have a chess program that can evaluate 5 million nodes per
second. Decide on a compact representation of a game state for storage
in a transposition table. About how many entries can you fit in a
1-gigabyte in-memory table? Will that be enough for the three minutes of
search allocated for one move? How many table lookups can you do in the
time it would take to do one evaluation? Now suppose the transposition
table is stored on disk. About how many evaluations could you do in the
time it takes to do one disk seek with standard disk hardware?</p>

<p><strong>5.17</strong> Suppose you have a chess program that can evaluate 10 million nodes per
second. Decide on a compact representation of a game state for storage
in a transposition table. About how many entries can you fit in a
2-gigabyte in-memory table? Will that be enough for the three minutes of
search allocated for one move? How many table lookups can you do in the
time it would take to do one evaluation? Now suppose the transposition
table is stored on disk. About how many evaluations could you do in the
time it takes to do one disk seek with standard disk hardware?</p>

<p>
<b id="trivial-chance-game-figure">Figure [trivial-chance-game-figure]</b> The complete game tree for a trivial game with chance nodes.
</p>

<p><img src="http://nalinc.github.io/aima-exercises/Jupyter%20notebook/figures/pruning.svg" alt="trivial-chance-game-figure"  style="width: 100%;" /></p>

<p><strong>5.18</strong> This question considers pruning in games with chance nodes.
Figure <a href="#trivial-chance-game-figure">trivial-chance-game-figure</a> shows the complete
game tree for a trivial game. Assume that the leaf nodes are to be
evaluated in left-to-right order, and that before a leaf node is
evaluated, we know nothing about its value—the range of possible values
is $-\infty$ to $\infty$.</p>

<ol style = " text-align: left; display: block ;" >
<li><p>Copy the figure, mark the value of all the internal nodes, and
indicate the best move at the root with an arrow.</p></li>

<li><p>Given the values of the first six leaves, do we need to evaluate the
seventh and eighth leaves? Given the values of the first seven
leaves, do we need to evaluate the eighth leaf? Explain
your answers.</p></li>

<li><p>Suppose the leaf node values are known to lie between –2 and 2
inclusive. After the first two leaves are evaluated, what is the
value range for the left-hand chance node?</p></li>

<li><p>Circle all the leaves that need not be evaluated under the
assumption in (c).</p></li>
</ol>

<p><strong>5.19</strong> Implement the expectiminimax algorithm and the *-alpha–beta algorithm,
which is described by @Ballard:1983, for pruning game trees with chance nodes. Try
them on a game such as backgammon and measure the pruning effectiveness
of *-alpha–beta.</p>

<p><strong>5.20</strong> [game-linear-transform] Prove that with a positive linear
transformation of leaf values (i.e., transforming a value $x$ to
$ax + b$ where $a > 0$), the choice of move remains unchanged in a game
tree, even when there are chance nodes.</p>

<p><strong>5.21</strong> [game-playing-monte-carlo-exercise]Consider the following procedure
for choosing moves in games with chance nodes:</p>

<ul>
<li><p>Generate some dice-roll sequences (say, 50) down to a suitable depth
(say, 8).</p></li>

<li><p>With known dice rolls, the game tree becomes deterministic. For each
dice-roll sequence, solve the resulting deterministic game tree
using alpha–beta.</p></li>

<li><p>Use the results to estimate the value of each move and to choose
the best.</p></li>
</ul>

<p>Will this procedure work well? Why (or why not)?</p>

<p><strong>5.22</strong> In the following, a “max” tree consists only of max nodes, whereas an
“expectimax” tree consists of a max node at the root with alternating
layers of chance and max nodes. At chance nodes, all outcome
probabilities are nonzero. The goal is to <em>find the value of the
root</em> with a bounded-depth search. For each of (a)–(f), either
give an example or explain why this is impossible.</p>

<ol>
<li><p>Assuming that leaf values are finite but unbounded, is pruning (as
in alpha–beta) ever possible in a max tree?</p></li>

<li><p>Is pruning ever possible in an expectimax tree under the same
conditions?</p></li>

<li><p>If leaf values are all nonnegative, is pruning ever possible in a
max tree? Give an example, or explain why not.</p></li>

<li><p>If leaf values are all nonnegative, is pruning ever possible in an
expectimax tree? Give an example, or explain why not.</p></li>

<li><p>If leaf values are all in the range $[0,1]$, is pruning ever
possible in a max tree? Give an example, or explain why not.</p></li>

<li><p>If leaf values are all in the range $[0,1]$, is pruning ever
possible in an expectimax tree?</p></li>

<li><p>Consider the outcomes of a chance node in an expectimax tree. Which
of the following evaluation orders is most likely to yield pruning
opportunities?</p>

<ol>
<li><p>Lowest probability first</p></li>

<li><p>Highest probability first</p></li>

<li><p>Doesn’t make any difference</p></li></ol></li>
</ol>

<p><strong>5.23</strong> In the following, a “max” tree consists only of max nodes, whereas an
“expectimax” tree consists of a max node at the root with alternating
layers of chance and max nodes. At chance nodes, all outcome
probabilities are nonzero. The goal is to <em>find the value of the
root</em> with a bounded-depth search.</p>

<ol>
<li><p>Assuming that leaf values are finite but unbounded, is pruning (as
in alpha–beta) ever possible in a max tree? Give an example, or
explain why not.</p></li>

<li><p>Is pruning ever possible in an expectimax tree under the same
conditions? Give an example, or explain why not.</p></li>

<li><p>If leaf values are constrained to be in the range $[0,1]$, is
pruning ever possible in a max tree? Give an example, or explain
why not.</p></li>

<li><p>If leaf values are constrained to be in the range $[0,1]$, is
pruning ever possible in an expectimax tree? Give an example
(qualitatively different from your example in (e), if any), or
explain why not.</p></li>

<li><p>If leaf values are constrained to be nonnegative, is pruning ever
possible in a max tree? Give an example, or explain why not.</p></li>

<li><p>If leaf values are constrained to be nonnegative, is pruning ever
possible in an expectimax tree? Give an example, or explain why not.</p></li>

<li><p>Consider the outcomes of a chance node in an expectimax tree. Which
of the following evaluation orders is most likely to yield pruning
opportunities: (i) Lowest probability first; (ii) Highest
probability first; (iii) Doesn’t make any difference?</p></li>
</ol>

<p><strong>5.24</strong> Which of the following are true and which are false? Give brief
explanations.</p>

<ol>
<li><p>In a fully observable, turn-taking, zero-sum game between two
perfectly rational players, it does not help the first player to
know what strategy the second player is using—that is, what move the
second player will make, given the first player’s move.</p></li>

<li><p>In a partially observable, turn-taking, zero-sum game between two
perfectly rational players, it does not help the first player to
know what move the second player will make, given the first
player’s move.</p></li>

<li><p>A perfectly rational backgammon agent never loses.</p></li>
</ol>

<p><strong>5.25</strong> Consider carefully the interplay of chance events and partial
information in each of the games in
Exercise [game-playing-chance-exercise].</p>

<ol>
<li><p>For which is the standard expectiminimax model appropriate?
Implement the algorithm and run it in your game-playing agent, with
appropriate modifications to the game-playing environment.</p></li>

<li><p>For which would the scheme described in
Exercise [game-playing-monte-carlo-exercise] be
appropriate?</p></li>

<li><p>Discuss how you might deal with the fact that in some of the games,
the players do not have the same knowledge of the current state.</p></li>
</ol>
                

        

</div>
      </div>
    </div>

    <hr>

    <!-- Footer -->
    <footer>
      <div class="container" >
        <div class="row">
          <div class="col-lg-8 col-md-10 mx-auto">
            <ul class="list-inline text-center">
              
        
              <li class="list-inline-item">
                <a href="https://github.com/aimacode/aima-exercises">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
                
                
            </ul>
            <p class="copyright text-muted">Copyright &copy; Peter Norvig</p>
          </div>
        </div>
      </div>
    </footer>


  </body>

</html>

       
                
                
		
